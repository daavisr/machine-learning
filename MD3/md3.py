# -*- coding: utf-8 -*-
"""MD3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EIt3VShlQYidFAWBMFLIMb0mLUlHlVqX
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_versionÂ 2.x

"""Download CSV"""

!wget https://github.com/daavisr/machine-learning/raw/master/MD3/reviews.csv -O reviews.csv

"""Read data from CSV"""

import pandas as pd
data = pd.read_csv('reviews.csv',delimiter=',',encoding='latin-1', usecols=[1,2,3,4,7])
answers = pd.read_csv('reviews.csv',delimiter=',',encoding='latin-1', usecols=[5,6]).astype('float')

data.head()

print(answers.groupby("Rating").count())
print(data['Review Text'].str.len().max())
print(data['Title'].str.len().max())

"""Prepare data"""

from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
import numpy as np
import pickle

def initTokenizer(data, load):
  if (load):
    !wget https://github.com/daavisr/machine-learning/raw/master/MD3/tokenizer_md3.pickle -O tokenizer_md3.pickle
    with open('tokenizer_md3.pickle', 'rb') as handle:
      tokenizer = pickle.load(handle)
    return tokenizer
  else:
    tokenizer = Tokenizer(num_words=3000)
    values = data['Title'].astype(str) + " " + data['Review Text']
    tokenizer.fit_on_texts(values.astype(str))
    return tokenizer

def tokenizeStringList(arr, maxLen):
  sequences = tok.texts_to_sequences(arr)
  return sequence.pad_sequences(sequences,maxlen=maxLen)

def createInputTextsArray(source):
  titleArr = source['Title'].astype('str')
  descArr = source['Review Text'].astype('str')
  seqMatrixTitles = tokenizeStringList(titleArr, 60)
  seqMatrixDesc = tokenizeStringList(descArr, 510)
  result = []
  for i in range(0, len(seqMatrixTitles)):
    result.append(np.concatenate((seqMatrixTitles[i], seqMatrixDesc[i])))
  return result

def createInputInfoArray(source):
  #cIds = source["Clothing ID"].astype('int')
  #ages = source["Age"].astype('int')
  posFeedbacks = source['Positive Feedback Count'].astype('int')
  result = []
  for i in range(0, len(posFeedbacks)):
    result.append(np.array([posFeedbacks[i]]));
  return result

def createAnswersRatingArray(source):
  return to_categorical(source["Rating"].astype('float'))

def createAnswersRecommendationArray(source):
  return source["Recommended IND"].astype('float').to_numpy()

tok = initTokenizer(data, True)
inputTextsArr = createInputTextsArray(data)
inputInfoArr = createInputInfoArray(data)
answersRatingArr = createAnswersRatingArray(answers)
answersRecommendationArr = createAnswersRecommendationArray(answers)

X_train1, X_test1, X_train2, X_test2, Y_train1, Y_test1, Y_train2, Y_test2 = train_test_split(inputTextsArr, inputInfoArr, answersRatingArr, answersRecommendationArr, test_size=0.2)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Model, Input
from tensorflow.keras.layers import Flatten
from keras.callbacks import EarlyStopping

def getModel(downloadPretrained):
  if(downloadPretrained):
    !wget https://github.com/daavisr/machine-learning/raw/master/MD3/model_md3.h5 -O model_md3.h5
    return keras.models.load_model('model_md3.h5')
  else:
    i_texts = Input(shape=570, name='i_texts')
    e = keras.layers.Embedding(10000, 256,)(i_texts)
    dr = keras.layers.Dropout(0.5)(e)
    l = keras.layers.Bidirectional(keras.layers.LSTM(128,  return_sequences=True))(dr)
    l2 = keras.layers.Bidirectional(keras.layers.LSTM(64,  return_sequences=True))(l)
    f = Flatten()(l2)

    i_info = Input(shape=1, name='i_info')

    c = keras.layers.Concatenate()([f, i_info])
    d1 = keras.layers.Dense(32, activation='relu')(c)
    dr2 = keras.layers.Dropout(0.2)(d1)
    output_rating = keras.layers.Dense(6, activation='softmax', name='output_rating')(d1)
    output_recommendation = keras.layers.Dense(1, activation='sigmoid', name='output_recommendation')(d1)

    losses_list = {
        'output_rating': 'binary_crossentropy',
        'output_recommendation': 'mean_squared_error'
    }

    metrics_list= {
        'output_rating': ['accuracy', keras.metrics.Recall(), keras.metrics.FalsePositives()],
        'output_recommendation': ['mae', keras.metrics.Recall(), keras.metrics.FalsePositives()]
    }

    model = Model(inputs=[i_texts, i_info], outputs=[output_rating, output_recommendation])
    model.compile(optimizer='adam', loss=losses_list, metrics=metrics_list)
    model.summary()
    model.fit([X_train1, X_train2], [Y_train1, Y_train2], epochs=40, batch_size=512, verbose=1, validation_data=([X_test1, X_test2], [Y_test1, Y_test2]), callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])
    return model

model = getModel(True)

"""Evaluate model on test data"""

model.evaluate([X_test1, X_test2], [Y_test1, Y_test2])

"""Test predictions & compare with correct answers"""

def predict(inputTexts, inputInfo):
  n = len(inputTexts)
  return model.predict({'i_texts': np.array(inputTexts[0:n]), 'i_info': np.array(inputInfo[0:n])})

def test(input1, input2, answers1, answers2):
  n = len(input1)
  predictions = predict(input1, input2)
  s = 0
  s2 = 0
  s3 = 0
  s4 = 0
  s5 = 0
  a = []
  for i in range(0, n):
    ratingPred = np.argmax(predictions[0][i])
    ratingCorrect = np.argmax(answers1[i])
    recommendPred = np.round(predictions[1][i]).tolist()[0]
    recommendCorrect = answers2[i]
    a.append(ratingPred)
    if (ratingPred == ratingCorrect):
      s = s + 1
    if (recommendPred == recommendCorrect):
      s2 = s2 + 1
    if (ratingPred == ratingCorrect and recommendPred == recommendCorrect):
      s3 = s3 + 1
    if(ratingPred == ratingCorrect or (ratingPred+1)== ratingCorrect or (ratingPred-1) == ratingCorrect):
      s4 = s4 + 1
    if((ratingPred == ratingCorrect or (ratingPred+1)== ratingCorrect or (ratingPred-1) == ratingCorrect) and recommendPred == recommendCorrect):
      s5 = s5 + 1

  print("Correct rating: ", s, "/", n)
  print("Correct recommendation: ", s2, "/", n)
  print("Correct both: ", s3, "/", n)
  print("Rating error <= 1 star: ", s4, "/", n)
  print("Rating error <= 1 star and correct recommendation: ", s5, "/", n)

  unique, counts = np.unique(a, return_counts=True)
  unique3, counts3 = np.unique(np.round(predictions[1]).astype(int), return_counts=True)
  print("Rating prediction distribution:")
  print(np.asarray((unique, counts)).T)
  print("Recommendation prediction distribution:")
  print(np.asarray((unique3, counts3)).T)

test(X_test1, X_test2, Y_test1, Y_test2)

"""My own reviews & their results"""

myData = [
[6, 'Very nice trousers', 'These jeans are the best purchase i have ever made! They fit me perfectly. Shipping was fast & customer service was great.'],
[0, 'Faulty item, such a disappointment', 'Bad product, even worse customer service. Shipment was late and seller did not even reply to my emails. When i finally received it the contents of package was ruined. Worst experience ever, i hate this store!'],
[2, 'Average quality for the spent money', 'Received these shoes yesterday, they are not excellent and the quality is not so great, but for this price you could expect that. At least the shipping was fast.'],
[0, 'Complete joke', 'These shoes have terrible quality problems, they split in half after a week. What a bad design! Further more, one shoe was one size larger than the other and one shoe lace was missing. Do not buy from this seller'],
[19, 'Reliable sunglasses', 'I always buy from this brand, they never fail to deliver the most excellent product!'],
[3, 'Did not arrive', 'The package was lost somewhere, it has been 3 months and i have not received it. At least, i received my money back']
]

myDf = pd.DataFrame(myData, columns=['Positive Feedback Count', 'Title', 'Review Text'])

myTextsArr = createInputTextsArray(myDf)
myInfoArr = createInputInfoArray(myDf)

myPred = predict(myTextsArr, myInfoArr)

for i in range(0, len(myData)):
  pred1 = np.argmax(myPred[0][i]) #Rating
  pred2 = np.round(myPred[1][i]).tolist()[0] #Recommended (0/1)
  print(pred1, pred2)

